{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xOrniRb0AVA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# First predict and select the images to be manually labeled/reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1lwKIqmq0OC",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = '/mnt/c/Users/Vasile Rotaru/Downloads/plaiul-20220605T045443Z-001/plaiul'\n",
    "MODELS_DIRECTORY = '/mnt/c/Users/Vasile Rotaru/Downloads/plaiul-20220605T045443Z-001/plaiul'\n",
    "ACTUAL_MODEL_FILENAME = 'deepforest_iter2'\n",
    "ENV='local'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_i3EMT170QH8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Manually label the selected samples via the LblImg tool\n",
    "In order to do this:\n",
    "1. Link the selected images from drive, to your computer and start LblImg in that folder.\n",
    "https://www.google.com/drive/download/\n",
    "2. Manually label/review them via LblImg.\n",
    "This will simultaneously update the labels on drive.\n",
    "Enter the folder where the predictions are made and run labelImg to open LabelImg in this folder, then start correcting the predictions.\n",
    "3. When finished, go to next step: Train on new samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsd-iNf0m8uU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Install dependecies... relevant in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "remiyxJpnufm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if ENV == 'colab':\n",
    "    !git clone https://github.com/ai-in-actiune/tree-counting-and-classification-in-images.git\n",
    "    !pip install -r tree-counting-and-classification-in-images/requirements.txt\n",
    "    !pip install --upgrade opencv-python setuptools==59.5.0 albumentations==1.0.3\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yw4D1-yy0Jwc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train on the output from LabelImg\n",
    "! Split into Train & Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make sure they were maually corrected before running these cells\n",
    "from pathlib import Path\n",
    "\n",
    "preds_path = Path(DATASET_DIRECTORY)\n",
    "train_csv_path = preds_path / 'train' / 'labels.csv'\n",
    "valid_csv_path = preds_path / 'valid' / 'labels.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepare the csvs from the xmls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "workdir = '/'\n",
    "if ENV == 'colab':\n",
    "    workdir = '/content/tree-counting-and-classification-in-images'\n",
    "elif ENV == 'local':\n",
    "    workdir = '..'\n",
    "os.chdir(workdir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import xml_utils\n",
    "\n",
    "def extract_labels_as_csvs(from_folder_path, to_file):\n",
    "    path = f\"{str(from_folder_path)}/*.xml\"\n",
    "    xmls_paths = sorted(glob(path))\n",
    "    accumulator_bboxes_dfs = []\n",
    "    for xml_path_str in tqdm(xmls_paths, desc=\"Converting xmls to csv for train eval\"):\n",
    "        xml_path = Path(xml_path_str)\n",
    "        xml_as_df = xml_utils.xml_to_annotations(str(xml_path))\n",
    "        accumulator_bboxes_dfs.append(xml_as_df)\n",
    "    folder_bboxes_df = pd.concat(accumulator_bboxes_dfs)\n",
    "    folder_bboxes_df.to_csv(to_file, index=False)\n",
    "\n",
    "\n",
    "extract_labels_as_csvs(train_csv_path.parent, train_csv_path)\n",
    "extract_labels_as_csvs(valid_csv_path.parent, valid_csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "manually create divide the manually tagged images into train/valid folders, then run the following cell"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#load the modules\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from deepforest import main \n",
    "# from deepforest import get_data\n",
    "# from deepforest import utilities\n",
    "# from deepforest import preprocess"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m = main.deepforest()\n",
    "# alternative2\n",
    "# m.use_release()\n",
    "# alternative1\n",
    "m.model.load_state_dict(\n",
    "    torch.load(\n",
    "        'deepforest_p5863_r6672'\n",
    "    )\n",
    ")\n",
    "m.config[\"train\"]['epochs'] = 33\n",
    "m.config[\"batch_size\"] = 3\n",
    "m.config[\"save-snapshot\"] = False\n",
    "m.config[\"train\"][\"csv_file\"] = str(train_csv_path)\n",
    "m.config[\"train\"][\"root_dir\"] = str(train_csv_path.parent)\n",
    "m.config[\"validation\"][\"csv_file\"] = str(valid_csv_path)\n",
    "m.config[\"validation\"][\"root_dir\"] = str(valid_csv_path.parent)\n",
    "m.config[\"gpus\"] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rbzmdIkbZFI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m.create_trainer()\n",
    "m.trainer.fit(m)\n",
    "m.evaluate(csv_file=m.config[\"validation\"][\"csv_file\"], root_dir=m.config[\"validation\"][\"root_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vO55OLxAyVEU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# decomment and use when predicting on plaiul fagului\n",
    "#predicted_raster = model.predict_tile(raster_path, return_plot = True, patch_size=400,patch_overlap=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvIdn-Fn2ikw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_path = Path(\n",
    "    '/content/drive/MyDrive/vork/ML/trees/tree-counting-and-classification-in-images/models/model1/'\n",
    ")\n",
    "m.trainer.save_checkpoint(save_path/\"checkpoint.pl\")\n",
    "torch.save(m.model.state_dict(),\n",
    "           save_path/'deepforest_p5933_r6815')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7wAIa-d2jNu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plaiul fagului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbnO8fsDzqTw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# rotate tif image in mac 30°\n",
    "# sips -r 30 plaiul_2.tif -o plaiul_rotated30.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXZNtopGyVqx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import rasterio\n",
    "# plaiul_sample = rasterio.open('/content/drive/MyDrive/vork/ML/trees/training/plaiul/plaiul_2.tif').read()\n",
    "# plaiul_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dceX49M6uP3p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Divide a large tile into smaller arrays. Each crop will be saved to file.\n",
    "# Parameters:\n",
    "# numpy_image – a numpy object to be used as a raster, usually opened from rasterio.open.read()\n",
    "# path_to_raster – (str): Path to a tile that can be read by rasterio on disk\n",
    "# annotations_file (str) – Path to annotations file (with column names) data in the format -> image_path, xmin, ymin, xmax, ymax, label\n",
    "# base_dir (str) – Where to save the annotations and image crops relative to current working dir\n",
    "# patch_size (int) – Maximum dimensions of square window\n",
    "# patch_overlap (float) – Percent of overlap among windows 0->1\n",
    "# allow_empty – If True, include images with no annotations to be included in the dataset\n",
    "# image_name (str) – If numpy_image arg is used, what name to give the raster?\n",
    "# Returns:\t\n",
    "# A pandas dataframe with annotations file for training.\n",
    "\n",
    "from deepforest import preprocess\n",
    "preprocess.split_raster(\n",
    "    annotations_file = f'{DATASET_DIRECTORY}/empty_annotations.csv',\n",
    "    path_to_raster=f'{DATASET_DIRECTORY}/plaiul_rotated30.tif',\n",
    "    base_dir=f'{DATASET_DIRECTORY}/crops',\n",
    "    patch_size=400,\n",
    "    patch_overlap=0.05,  # buffer percentage of patch_size. (patch_overlap * patch_size) should equal the size of a tree\n",
    "    allow_empty=True,  # allow empty, since plaieul fagului is not yet annotated\n",
    ")#image_name=None)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyORBsYzw+G78RmtSYj1oiE9",
   "collapsed_sections": [],
   "mount_file_id": "17fFU00651remaTOoKBjMas4oKH63ENC6",
   "name": "1.0-foc-AZ_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}