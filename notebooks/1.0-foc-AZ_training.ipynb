{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1.0-foc-AZ_training.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"17fFU00651remaTOoKBjMas4oKH63ENC6","authorship_tag":"ABX9TyORBsYzw+G78RmtSYj1oiE9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# First predict and select the images to be manually labeled/reviewed"],"metadata":{"id":"8xOrniRb0AVA"}},{"cell_type":"code","source":["# ! cd /content/drive/MyDrive/vork/ML/trees/tree-counting-and-classification-in-images/src/utils\n","# ! sh targetted_training.sh /content/drive/MyDrive/vork/ML/trees/train_data_folder/ /content/drive/MyDrive/vork/ML/trees/train_data_to_review/ 20\n","! cd /content/drive/MyDrive/vork/ML/trees/tree-counting-and-classification-in-images/src/utils ; \\\n","sh /content/drive/MyDrive/vork/ML/trees/tree-counting-and-classification-in-images/src/utils/targetted_training.sh \\\n","/content/drive/MyDrive/vork/ML/trees/training/plaiul/crops/ \\\n","/content/drive/MyDrive/vork/ML/trees/training/plaiul/preds/ \\\n","30\n"],"metadata":{"id":"W1lwKIqmq0OC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Manually label the selected samples via the LblImg tool\n","In order to do this:\n","1. Link the selected images from drive, to your computer and start LblImg in that folder.\n","https://www.google.com/drive/download/\n","1. Manually label/review them via LblImg.  \n","This will simultaneously update the labels on drive.\n","Enter the\n","```\n","/content/drive/MyDrive/vork/ML/trees/train_data_to_review/\n","``` folder and run labelImg to open LabelImg in this folder, then start correcting the predictions.\n","1. When finished, go to next step: Train on new samples."],"metadata":{"id":"_i3EMT170QH8"}},{"cell_type":"markdown","source":["# Install dependecies... relevant in colab"],"metadata":{"id":"tsd-iNf0m8uU"}},{"cell_type":"code","source":["! pip install -r /content/drive/MyDrive/vork/ML/trees/tree-counting-and-classification-in-images/requirements.txt\n","! pip install --upgrade opencv-python setuptools==59.5.0 albumentations==1.0.3"],"metadata":{"id":"remiyxJpnufm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train on the output from LabelImg\n","! Split into Train & Valid"],"metadata":{"id":"yw4D1-yy0Jwc"}},{"cell_type":"code","source":["# make sure they were maually corrected before running these cells\n","from pathlib import Path\n","\n","preds_path = Path('/content/drive/MyDrive/vork/ML/trees/training/plaiul/preds/')\n","\n","train_csv_path = preds_path.parent / 'train' / 'labels.csv'\n","valid_csv_path = preds_path.parent / 'valid' / 'labels.csv'"],"metadata":{"id":"N-EMktg7imoj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Prepare the csvs from the xmls"],"metadata":{"id":"avvPCfuzb3jV"}},{"cell_type":"code","source":["cd /content/drive/MyDrive/vork/ML/trees/tree-counting-and-classification-in-images/src/utils"],"metadata":{"id":"scrbUeK_1Z-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from glob import glob\n","from tqdm import tqdm\n","import pandas as pd\n","# internal import\n","import xml_utils\n","\n","def extract_labels_as_csvs(from_folder_path, to_file):\n","  xmls_paths = sorted(glob(f\"{str(from_folder_path)}/*.xml\"))\n","  accumulator_bboxes_dfs = []\n","  for xml_path_str in tqdm(xmls_paths, desc=\"Converting xmls to csv for train eval\"):\n","    xml_path = Path(xml_path_str)\n","    xml_as_df = xml_utils.xml_to_annotations(str(xml_path))\n","    accumulator_bboxes_dfs.append(xml_as_df)\n","  folder_bboxes_df = pd.concat(accumulator_bboxes_dfs)\n","  folder_bboxes_df.to_csv(to_file, index=False)"],"metadata":{"id":"lWw93xCech6V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["manually create divide the manually tagged images into train/valid folders, then run the following cell"],"metadata":{"id":"tBc-f3en0XMP"}},{"cell_type":"code","source":["extract_labels_as_csvs(train_csv_path.parent, train_csv_path)\n","extract_labels_as_csvs(valid_csv_path.parent, valid_csv_path)"],"metadata":{"id":"vHQhhgq9eiu8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"ikIrx9WIb4EV"}},{"cell_type":"code","source":["%matplotlib inline\n","%reload_ext autoreload\n","%autoreload 2"],"metadata":{"id":"gb76CCXapBYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLoXtcQ1m62N"},"outputs":[],"source":["#load the modules\n","import os\n","import time\n","import numpy as np\n","from pathlib import Path\n","\n","import torch\n","from deepforest import main \n","# from deepforest import get_data\n","# from deepforest import utilities\n","# from deepforest import preprocess"]},{"cell_type":"code","source":["m = main.deepforest()\n","# alternative2\n","# m.use_release()\n","# alternative1\n","m.model.load_state_dict(\n","    torch.load(\n","        '/content/drive/MyDrive/vork/ML/trees/tree-counting-and-classification-in-images/models/model1/deepforest_p5863_r6672'\n","    )\n",")\n","m.config[\"train\"]['epochs'] = 33\n","m.config[\"batch_size\"] = 3\n","m.config[\"save-snapshot\"] = False\n","m.config[\"train\"][\"csv_file\"] = str(train_csv_path)\n","m.config[\"train\"][\"root_dir\"] = str(train_csv_path.parent)\n","m.config[\"validation\"][\"csv_file\"] = str(valid_csv_path)\n","m.config[\"validation\"][\"root_dir\"] = str(valid_csv_path.parent)\n","m.config[\"gpus\"] = 1"],"metadata":{"id":"jyNJEzqQrPYl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650206841703,"user_tz":-180,"elapsed":1146,"user":{"displayName":"Octav Florescu","userId":"16322492819797755651"}},"outputId":"07698d04-2a0f-4d6d-d0b5-52109234a539"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading config file: /usr/local/lib/python3.7/dist-packages/deepforest/data/deepforest_config.yml\n"]}]},{"cell_type":"code","source":["m.create_trainer()\n","m.trainer.fit(m)\n","m.evaluate(csv_file=m.config[\"validation\"][\"csv_file\"], root_dir=m.config[\"validation\"][\"root_dir\"])"],"metadata":{"id":"7rbzmdIkbZFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# decomment and use when predicting on plaiul fagului\n","#predicted_raster = model.predict_tile(raster_path, return_plot = True, patch_size=400,patch_overlap=0.05)"],"metadata":{"id":"vO55OLxAyVEU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_path = Path(\n","    '/content/drive/MyDrive/vork/ML/trees/tree-counting-and-classification-in-images/models/model1/'\n",")\n","m.trainer.save_checkpoint(save_path/\"checkpoint.pl\")\n","torch.save(m.model.state_dict(),\n","           save_path/'deepforest_p5933_r6815')"],"metadata":{"id":"DvIdn-Fn2ikw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Plaiul fagului"],"metadata":{"id":"H7wAIa-d2jNu"}},{"cell_type":"code","source":["# rotate tif image in mac 30°\n","# sips -r 30 plaiul_2.tif -o plaiul_rotated30.tif"],"metadata":{"id":"JbnO8fsDzqTw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import rasterio\n","# plaiul_sample = rasterio.open('/content/drive/MyDrive/vork/ML/trees/training/plaiul/plaiul_2.tif').read()\n","# plaiul_sample.shape"],"metadata":{"id":"LXZNtopGyVqx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Divide a large tile into smaller arrays. Each crop will be saved to file.\n","# Parameters:\t\n","# numpy_image – a numpy object to be used as a raster, usually opened from rasterio.open.read()\n","# path_to_raster – (str): Path to a tile that can be read by rasterio on disk\n","# annotations_file (str) – Path to annotations file (with column names) data in the format -> image_path, xmin, ymin, xmax, ymax, label\n","# base_dir (str) – Where to save the annotations and image crops relative to current working dir\n","# patch_size (int) – Maximum dimensions of square window\n","# patch_overlap (float) – Percent of overlap among windows 0->1\n","# allow_empty – If True, include images with no annotations to be included in the dataset\n","# image_name (str) – If numpy_image arg is used, what name to give the raster?\n","# Returns:\t\n","# A pandas dataframe with annotations file for training.\n","\n","from deepforest import preprocess\n","preprocess.split_raster(annotations_file = '/content/drive/MyDrive/vork/ML/trees/training/plaiul/empty_annotations.csv',\n","                        path_to_raster='/content/drive/MyDrive/vork/ML/trees/training/plaiul/plaiul_rotated30.tif',\n","                        base_dir='/content/drive/MyDrive/vork/ML/trees/training/plaiul/crops',\n","                        patch_size=400,\n","                        patch_overlap=0.05,  # buffer percentage of patch_size. (patch_overlap * patch_size) should equal the size of a tree\n","                        allow_empty=True,  # allow empty, since plaieul fagului is not yet annotated\n","                        )#image_name=None)\n"],"metadata":{"id":"dceX49M6uP3p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Predict & extract 30 most unsure samples"],"metadata":{"id":"F3_LKX_Zfzcb"}},{"cell_type":"code","source":["! cd /content/drive/MyDrive/vork/ML/trees/tree-counting-and-classification-in-images/src/utils ; \\\n","sh /content/drive/MyDrive/vork/ML/trees/tree-counting-and-classification-in-images/src/utils/targetted_training.sh \\\n","/content/drive/MyDrive/vork/ML/trees/training/plaiul/crops/ \\\n","/content/drive/MyDrive/vork/ML/trees/training/plaiul/preds/ \\\n","30"],"metadata":{"id":"5KtZjsq0fwqS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Drive connect"],"metadata":{"id":"pE0E_z3Mf_SC"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3ESJtr6XHo9","executionInfo":{"status":"ok","timestamp":1647797128453,"user_tz":-120,"elapsed":9668,"user":{"displayName":"Octav Florescu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrvoHwhCBJpLP0FTeR3YwwXZYfF74CTPX_LiCaKA=s64","userId":"16322492819797755651"}},"outputId":"c15ff641-eb56-4f43-953d-a3f4ea3c0979"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]}]}